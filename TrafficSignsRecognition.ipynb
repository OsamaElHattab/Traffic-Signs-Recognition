{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commonfunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Annotation => filename ; y ; x ; x_min ; y_min ; x_max ; y_max ; category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (256, 256)  # To resize all images to 64x64\n",
    "DATASET_PATH = \"TSRD_Train\"  # Path to your dataset folder\n",
    "ANNOTATION_FILE = \"TSRD_Train_Annotation/TsignRecgTrain4170Annotation.txt\"  # Path to the annotation file\n",
    "SAVE_PATH = \"processed_data.npz\"  # File to save the processed dataset (NPZ to store NumPy arrays)\n",
    "TEST_DATASET_PATH = \"TSRD_Test\"  # Path to your test dataset folder\n",
    "TEST_ANNOTATION_FILE = \"TSRD_Test_Annotation/TsignRecgTest1994Annotation.txt\"  # Path to the test annotation file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse annotation file #####################################################\n",
    "def parse_annotations(annotation_file):\n",
    "    annotations = []\n",
    "    with open(annotation_file, \"r\") as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(\";\")\n",
    "            filename = parts[0]\n",
    "            y_axis = int(parts[1])\n",
    "            x_axis = int(parts[2])\n",
    "            bound_x_min = int(parts[3])\n",
    "            bound_y_min = int(parts[4])\n",
    "            bound_x_max = int(parts[5])\n",
    "            bound_y_max = int(parts[6])\n",
    "            label = int(parts[7])\n",
    "            # if label == 54:\n",
    "            #     continue\n",
    "            annotations.append({\n",
    "                \"filename\": filename,\n",
    "                \"y_axis\": y_axis,\n",
    "                \"x_axis\": x_axis,\n",
    "                \"bound_x_min\": bound_x_min,\n",
    "                \"bound_y_min\": bound_y_min,\n",
    "                \"bound_x_max\": bound_x_max,\n",
    "                \"bound_y_max\": bound_y_max,\n",
    "                \"label\": label\n",
    "            })\n",
    "    return annotations\n",
    "\n",
    "\n",
    "# Function to load images ################################################\n",
    "def load_images(image_folder, annotations):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for ann in annotations:\n",
    "        # Get the image path\n",
    "        img_path = os.path.join(image_folder, ann[\"filename\"])\n",
    "        # Read the image\n",
    "        img = io.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load image: {img_path}\")\n",
    "            continue\n",
    "        images.append(img)\n",
    "        labels.append(ann[\"label\"])\n",
    "    return images, labels\n",
    "\n",
    "# get the acutal labels of the test dataset\n",
    "def get_actual_labels(TEST_DATASET_PATH):\n",
    "    actual_labels = []\n",
    "    for filename in os.listdir(TEST_DATASET_PATH):\n",
    "        label = int(filename.split(\"_\")[0])\n",
    "        actual_labels.append(label)\n",
    "    return actual_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import disk, opening, closing\n",
    "# Function to load and preprocess images ################################################\n",
    "def preprocess_images(image_folder, annotations, image_size):\n",
    "\n",
    "    # load images and labels\n",
    "    images, labels = load_images(image_folder, annotations)\n",
    "\n",
    "    processed_images = []\n",
    "\n",
    "    for i in range(len(images)):\n",
    "    # for i in range(10 , 20):\n",
    "\n",
    "        ann = annotations[i]\n",
    "        img = images[i]\n",
    "\n",
    "\n",
    "        # # Crop the bounding box\n",
    "        cropped_img = img[ann[\"bound_y_min\"]:ann[\"bound_y_max\"], ann[\"bound_x_min\"]:ann[\"bound_x_max\"]]\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray_image = cv.cvtColor(cropped_img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply Gaussian filter with sigma=3\n",
    "        gaussian_blur = cv.GaussianBlur(gray_image, (5, 5), sigmaX=1, sigmaY=1)\n",
    "        \n",
    "        # Perform opening morphology using a disk-shaped structuring element\n",
    "        structuring_element = disk(4)  # Disk of radius 5\n",
    "        opened_image = opening(gaussian_blur, structuring_element)\n",
    "\n",
    "\n",
    "        # # histogram equalization to all the channels\n",
    "        # cropped_img[:, :, 2] = histogram_eq(cropped_img[:, :, 2])\n",
    "        # cropped_img[:, :, 1] = histogram_eq(cropped_img[:, :, 1])\n",
    "        # cropped_img[:, :, 0] = histogram_eq(cropped_img[:, :, 0])\n",
    "\n",
    "\n",
    "        # # Convert to HSV\n",
    "        # hsv = cv.cvtColor(cropped_img, cv.COLOR_RGB2HSV)\n",
    "\n",
    "        # # Define Red Color Range\n",
    "        # lower_red1 = np.array([0, 100, 100])\n",
    "        # upper_red1 = np.array([10, 255, 255])\n",
    "        # lower_red2 = np.array([160, 100, 100])\n",
    "        # upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "        # # Define Blue Color Range\n",
    "        # lower_blue = np.array([70, 100, 100])\n",
    "        # upper_blue = np.array([160, 255, 255])\n",
    "\n",
    "        # # Create Red Masks\n",
    "        # mask_red1 = cv.inRange(hsv, lower_red1, upper_red1)\n",
    "        # mask_red2 = cv.inRange(hsv, lower_red2, upper_red2)\n",
    "        # mask_red = mask_red1 + mask_red2  # Combine two red masks\n",
    "\n",
    "        # # Create Blue Mask\n",
    "        # mask_blue = cv.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "        # red_pixels = np.sum(mask_red > 0)\n",
    "        # blue_pixels = np.sum(mask_blue > 0)\n",
    "\n",
    "        # if red_pixels > blue_pixels:\n",
    "        #     print(\"Dominant Color: Red\")\n",
    "        # elif blue_pixels > red_pixels:\n",
    "        #     print(\"Dominant Color: Blue\")\n",
    "        # else:\n",
    "        #     print(\"No dominant color detected\")\n",
    "\n",
    "        # show_images([cropped_img, mask_red, mask_blue], [\"Cropped Image\", \"Red Mask\", \"Blue Mask\"])\n",
    "\n",
    "        # # Convert to grayscale\n",
    "        # gray_img = (rgb2gray(cropped_img)*255).astype(np.uint8)\n",
    "        # print (gray_img)\n",
    "\n",
    "        # # histogram equalization\n",
    "        # hist_eq_img = histogram_eq(gray_img)\n",
    "        # show_images([gray_img, hist_eq_img], [\"Original\", \"Histogram Equalized\"])\n",
    "\n",
    "        # # increase the saturation of the image\n",
    "        # hsv_img = cv.cvtColor(cropped_img, cv.COLOR_RGB2HSV)\n",
    "        # hsv_img[:, :, 1] = hsv_img[:, :, 1] * 1.5\n",
    "        # increased_saturation_img = cv.cvtColor(hsv_img, cv.COLOR_HSV2RGB)\n",
    "        # show_images([cropped_img, increased_saturation_img], [\"Original\", \"Increased Saturation\"])\n",
    "\n",
    "        # Resize the image\n",
    "        resized_img = cv.resize(opened_image, image_size, interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "        # crop the circluar region with center equals the center of the bounding box and radius equals the half of the bounding box width\n",
    "        mask1 = np.zeros_like(resized_img)\n",
    "        center = (int(resized_img.shape[1]/2), int(resized_img.shape[0]/2))\n",
    "        radius = int(resized_img.shape[1]/2)\n",
    "        mask1 = cv.circle(mask1, center, radius, (255, 255, 255), -1)\n",
    "        masked_img = cv.bitwise_and(resized_img, mask1)\n",
    "        # show_images([img, resized_img ,  masked_img], [\"Original\", \"Resized\" , \"Masked\"])\n",
    "\n",
    "        # Normalize pixel values\n",
    "        # normalized_img = masked_img / 255.0\n",
    "        normalized_img = masked_img\n",
    "\n",
    "        # show_images([img, cropped_img, resized_img, normalized_img], [\"Original\", \"Cropped\", \"Resized\", \"Normalized\"])\n",
    "        # show_images([img, cropped_img, gaussian_blur, opened_image, resized_img, normalized_img], [\"Original\", \"cropped_img\", \"gaussian_blur\", \"opened_image\", \"resized_img\",  \"Normalized\"])\n",
    "\n",
    "        processed_images.append(normalized_img)\n",
    "\n",
    "    # # Convert to NumPy arrays\n",
    "    processed_images = np.array(processed_images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return processed_images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape-Based Features (edge detection, Hough transform)\n",
    "\n",
    "#canny edge detection\n",
    "def canny_edge_detection(image):\n",
    "    edges = cv.Canny((image * 255).astype(np.uint8), 40, 80)\n",
    "    return edges\n",
    "\n",
    "# Lines Hough transform\n",
    "def lines_hough_transform(image):\n",
    "    gray = rgb2gray(image)\n",
    "    edges = canny_edge_detection(gray)\n",
    "    lines = cv.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=45, minLineLength=20, maxLineGap=10)\n",
    "    return lines\n",
    "\n",
    "# Circles Hough transform\n",
    "def circles_hough_transform(image):\n",
    "    # gray = rgb2gray(image)\n",
    "    edges = canny_edge_detection(image)\n",
    "    circles = cv.HoughCircles(edges, cv.HOUGH_GRADIENT, dp=3, minDist=300, param1=50, param2=30, minRadius=30, maxRadius=150)\n",
    "    return circles\n",
    "\n",
    "# HOG\n",
    "def extract_hog_features(image):\n",
    "    # gray = rgb2gray(image)\n",
    "    hog_features = hog(image, \n",
    "                       orientations=9, \n",
    "                       pixels_per_cell=(8, 8), \n",
    "                       cells_per_block=(2, 2), \n",
    "                       block_norm='L2-Hys', \n",
    "                       visualize=False, \n",
    "                       feature_vector=True)\n",
    "    return hog_features\n",
    "\n",
    "\n",
    "# Keypoint-Based Features\n",
    "\n",
    "# Harris corner detection\n",
    "def harris_corner_detection(image):\n",
    "    gray = rgb2gray(image)\n",
    "    gray = np.float32(gray)\n",
    "    dst = cv.cornerHarris(gray, blockSize=2, ksize=3, k=0.04)\n",
    "    return dst\n",
    "\n",
    "# SIFT \n",
    "def sift_features(image):\n",
    "    # image = np.uint8(image * 255)\n",
    "    # gray = rgb2gray(image)\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classificaion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocabulary using KMeans clustering\n",
    "def create_vocabulary(descriptors, k):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(descriptors)\n",
    "    return kmeans\n",
    "\n",
    "# generate BoVW histograms\n",
    "def generate_bovw_histograms(descriptors_list, kmeans, k):\n",
    "    histograms = []\n",
    "    for descriptors in descriptors_list:\n",
    "        if descriptors is not None:\n",
    "            words = kmeans.predict(descriptors)\n",
    "            histogram, _ = np.histogram(words, bins=np.arange(k+1), density=True)\n",
    "        else:\n",
    "            histogram = np.zeros(k)\n",
    "        histograms.append(histogram)\n",
    "    return np.array(histograms)\n",
    "\n",
    "# generate BoVW histograms for one image\n",
    "def generate_bovw_histograms_for_one_image(descriptors, kmeans, k):\n",
    "    if descriptors is not None:\n",
    "            words = kmeans.predict(descriptors)\n",
    "            histogram, _ = np.histogram(words, bins=np.arange(k+1), density=True)\n",
    "    else:\n",
    "        histogram = np.zeros(k)\n",
    "    return np.array(histogram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train ():\n",
    "    \n",
    "    # Parse annotations\n",
    "    annotations = parse_annotations(ANNOTATION_FILE)\n",
    "\n",
    "    # Load and preprocess images\n",
    "    images, labels = preprocess_images(DATASET_PATH, annotations, IMAGE_SIZE)\n",
    "\n",
    "    print(\"Succesfully preprocessed images\")\n",
    "    print(\"Extracting features...\")\n",
    "\n",
    "    # descreptors list for all images\n",
    "    descriptors_list = []\n",
    "    new_labels = []\n",
    "\n",
    "    images_histograms = []\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        img = images[i]\n",
    "        label = labels[i]\n",
    "\n",
    "\n",
    "        # Apply hog features\n",
    "        hog = extract_hog_features(img)\n",
    "        images_histograms.append(hog)\n",
    "\n",
    "        # Apply Canny edge detection\n",
    "        # edges = canny_edge_detection(img)\n",
    "\n",
    "        # # Apply Hough transform for lines\n",
    "        # lines = lines_hough_transform(img)\n",
    "        # if lines is not None:\n",
    "        #     for line in lines:\n",
    "        #         x1, y1, x2, y2 = line[0]\n",
    "        #         cv.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        # # Apply Hough transform for circles\n",
    "        # detected_circles = circles_hough_transform(img)\n",
    "\n",
    "        # if detected_circles is not None: \n",
    "        #     print (\"detected_circles\", detected_circles)\n",
    "\n",
    "        #     # Convert the circle parameters a, b and r to integers. \n",
    "        #     detected_circles = np.uint16(np.around(detected_circles)) \n",
    "\n",
    "        #     for pt in detected_circles[0, :]: \n",
    "        #         a, b, r = pt[0], pt[1], pt[2] \n",
    "\n",
    "        #         # Draw the circumference of the circle. \n",
    "        #         cv.circle(img, (a, b), r, (0, 255, 0), 2) \n",
    "\n",
    "        #         # Draw a small circle (of radius 1) to show the center. \n",
    "        #         cv.circle(img, (a, b), 1, (0, 0, 255), 3) \n",
    "\n",
    "        # # apply Harris corner detection\n",
    "        # dst = harris_corner_detection(img)\n",
    "        # dst = cv.dilate(dst, None)\n",
    "        # img[dst > 0.01 * dst.max()] = [0, 255, 0]\n",
    "\n",
    "        # print (\"img\", img * 255)\n",
    "\n",
    "        # # apply SIFT\n",
    "        # keypoints, descriptors = sift_features(img)\n",
    "        # if descriptors is not None:\n",
    "        #     descriptors_list.append(descriptors)\n",
    "        #     new_labels.append(label)\n",
    "\n",
    "\n",
    "        # img=cv.drawKeypoints(img, keypoints,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        # cv.imwrite('sift_keypoints.jpg',img)\n",
    "        # show_images([img], [\"SIFT\"])\n",
    "\n",
    "        # show_images([img, edges], [\"Original\", \"Edges\"])\n",
    "        # print(f\"Label: {label}\")\n",
    "\n",
    "\n",
    "    # # stack all descriptors\n",
    "    # stack_descriptors = np.vstack(descriptors_list)\n",
    "\n",
    "    # # create vocabulary using KMeans clustering\n",
    "    # k = 290 # number of clusters (total number of keypoints / number of dataset images * number of classes) (Average)\n",
    "    # kmeans = create_vocabulary(stack_descriptors, k)\n",
    "\n",
    "    # print(\"descriptors_list_dimentions\", len(descriptors_list))\n",
    "    # print (\"stack_descriptors_shape\", stack_descriptors.shape)\n",
    "    # print (\"kmeans\", kmeans)\n",
    "\n",
    "    # pca = PCA(n_components=2)\n",
    "    # reduced_data = pca.fit_transform(descriptors)\n",
    "\n",
    "    # # Now separate the data, Note the flatten()\n",
    "    # A = stack_descriptors[labels.ravel()==0]\n",
    "    # B = stack_descriptors[labels.ravel()==1]\n",
    "\n",
    "    # # Plot the data\n",
    "    # plt.scatter(A[:,0],A[:,1])\n",
    "    # plt.scatter(B[:,0],B[:,1],c = 'r')\n",
    "    # plt.scatter(centers[:,0],centers[:,1],s = 80,c = 'y', marker = 's')\n",
    "    # plt.xlabel('Height'),plt.ylabel('Weight')\n",
    "    # plt.show()\n",
    "\n",
    "    # Generate BoVW Histograms for Each Image\n",
    "    # print(\"Generating BoVW histograms...\")\n",
    "    # images_histograms = generate_bovw_histograms(descriptors_list, kmeans, k)\n",
    "    # print (\"images_histograms_shape\", images_histograms.shape)\n",
    "    # for histogram in images_histograms:\n",
    "    #     print (\"histogram\", histogram)\n",
    "    #     print (\"histogram_shape\", histogram.shape)\n",
    "\n",
    "    # images_histograms = []\n",
    "    # for discriptor in descriptors_list:\n",
    "    #     # Handle edge case where no descriptors are found\n",
    "    #     if discriptor is None:\n",
    "    #         discriptor = np.zeros((1, 128), dtype=np.float32)\n",
    "\n",
    "    #     # Assign descriptors to the nearest cluster center (for each keypoint in the descriptor, find the nearest cluster center (nears word))\n",
    "    #     words = kmeans.predict(discriptor)\n",
    "\n",
    "    #     # Build histogram of visual words\n",
    "    #     histogram = np.zeros(kmeans.n_clusters, dtype=np.float32)\n",
    "    #     for word in words:\n",
    "    #         histogram[word] += 1\n",
    "    #     images_histograms.append(histogram)\n",
    "\n",
    "\n",
    "    # standardize the features\n",
    "    # images_histograms = StandardScaler().fit_transform(images_histograms)\n",
    "\n",
    "    \n",
    "\n",
    "    # Train SVM classifier\n",
    "    svm = SVC(C=0.0008, kernel=\"linear\", random_state=50)\n",
    "    svm.fit(images_histograms, labels)\n",
    "\n",
    "\n",
    "    return svm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (svm):\n",
    "\n",
    "    predicted_labels = []\n",
    "\n",
    "    actual_labels = get_actual_labels(TEST_DATASET_PATH)\n",
    "    \n",
    "    # try for the the blind test set folder\n",
    "    # Load images\n",
    "    blind_test_images = []\n",
    "    for filename in os.listdir(TEST_DATASET_PATH):\n",
    "        img_path = os.path.join(TEST_DATASET_PATH, filename)\n",
    "        img = io.imread(img_path)\n",
    "        blind_test_images.append(img)\n",
    "\n",
    "\n",
    "\n",
    "    # # Preprocess images\n",
    "    # blind_test_images = np.array(blind_test_images)\n",
    "    # blind_test_images = blind_test_images / 255.0\n",
    "\n",
    "    # Extract SIFT features\n",
    "    blind_test_descriptors_list = []\n",
    "    # print(\"imgs shape\", len(blind_test_images))\n",
    "    # print(\"actual labels\", len(actual_labels))\n",
    "\n",
    "    # for i, img in enumerate(blind_test_images):\n",
    "    # for i in range(400, 450):\n",
    "    for i in range(len(blind_test_images)):\n",
    "        img = blind_test_images[i]\n",
    "\n",
    "        # if actual_labels[i] == 54:\n",
    "        #     continue\n",
    "\n",
    "        # image resizing\n",
    "        img = cv.resize(img, IMAGE_SIZE, interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "        gray_image = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply Gaussian filter with sigma=3\n",
    "        gaussian_blur = cv.GaussianBlur(gray_image, (7, 7), sigmaX=1, sigmaY=1)\n",
    "        \n",
    "        # Perform opening morphology using a disk-shaped structuring element\n",
    "        structuring_element = disk(4)  # Disk of radius 5\n",
    "        opened_image = opening(gaussian_blur, structuring_element)\n",
    "\n",
    "        # hough circle\n",
    "        detected_circles = circles_hough_transform(opened_image)\n",
    "\n",
    "        # crop the image to the circular region if exists\n",
    "        if detected_circles is not None:\n",
    "            # print (\"detected_circles\", detected_circles)\n",
    "            for pt in detected_circles[0, :]: \n",
    "                a, b, r = pt[0], pt[1], pt[2] \n",
    "                # print (\"a, b, r\", a, b, r)\n",
    "                mask1 = np.zeros_like(img)\n",
    "                mask1 = cv.circle(mask1, (int(a), int(b)), int(r), (255, 255, 255), -1)\n",
    "                masked_img = cv.bitwise_and(img, mask1)\n",
    "                img = masked_img\n",
    "\n",
    "        # if detected_circles is not None: \n",
    "        #     # print (\"detected_circles\", detected_circles)\n",
    "\n",
    "        #     # Convert the circle parameters a, b and r to integers. \n",
    "        #     detected_circles = np.uint16(np.around(detected_circles)) \n",
    "\n",
    "        #     for pt in detected_circles[0, :]: \n",
    "        #         a, b, r = pt[0], pt[1], pt[2] \n",
    "\n",
    "        #         # Draw the circumference of the circle. \n",
    "        #         cv.circle(img, (a, b), r, (0, 255, 0), 2) \n",
    "\n",
    "        #         # Draw a small circle (of radius 1) to show the center. \n",
    "        #         cv.circle(img, (a, b), 1, (0, 0, 255), 3)\n",
    "\n",
    "        # show_images([img], [\"Hough Circles\"]) \n",
    "\n",
    "\n",
    "        # # apply SIFT\n",
    "        # keypoints, descriptors = sift_features(img)\n",
    "        # # blind_test_descriptors_list.append(descriptors)\n",
    "\n",
    "        # # img=cv.drawKeypoints(img, keypoints,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        # # cv.imwrite('sift_keypoints.jpg',img)\n",
    "        # # show_images([img], [\"SIFT\"])\n",
    "\n",
    "        # # Handle edge case where no descriptors are found\n",
    "        # if descriptors is None:\n",
    "        #     descriptors = np.zeros((1, 128), dtype=np.float32)\n",
    "\n",
    "        # # Assign descriptors to the nearest cluster center (for each keypoint in the descriptor, find the nearest cluster center (nears word))\n",
    "        # words = kmeans.predict(descriptors)\n",
    "\n",
    "        # # Build histogram of visual words\n",
    "        # histogram = np.zeros(kmeans.n_clusters, dtype=np.float32)\n",
    "        # for word in words:\n",
    "        #     histogram[word] += 1\n",
    "\n",
    "        # Normalize histogram\n",
    "        # histogram /= len(words)\n",
    "        # print (\"histogram\", histogram)\n",
    "        # img = img / 255.0\n",
    "        hog = extract_hog_features(opened_image)\n",
    "\n",
    "        # predict the label\n",
    "        predicted_label = svm.predict(hog.reshape(1, -1))\n",
    "        predicted_labels.append(predicted_label[0])\n",
    "        # print(f\"Predicted label: {predicted_label[0]}\")\n",
    "\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Predict with one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(svm, img):\n",
    "    \"\"\"\n",
    "    Predict the label of a single image using the given SVM model.\n",
    "\n",
    "    Args:\n",
    "        svm: Trained SVM model.\n",
    "        img: Input image as a numpy array.\n",
    "\n",
    "    Returns:\n",
    "        Predicted label for the input image.\n",
    "    \"\"\"\n",
    "    # Resize the image to match the expected dimensions\n",
    "    img = cv.resize(img, IMAGE_SIZE, interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray_image = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian filter with sigma=3\n",
    "    gaussian_blur = cv.GaussianBlur(gray_image, (7, 7), sigmaX=1, sigmaY=1)\n",
    "\n",
    "    # Perform opening morphology using a disk-shaped structuring element\n",
    "    structuring_element = disk(4)  # Disk of radius 4\n",
    "    opened_image = opening(gaussian_blur, structuring_element)\n",
    "\n",
    "    # Perform Hough Circle Transform\n",
    "    detected_circles = circles_hough_transform(opened_image)\n",
    "\n",
    "    # Crop the image to the circular region if circles are detected\n",
    "    if detected_circles is not None:\n",
    "        for pt in detected_circles[0, :]: \n",
    "            a, b, r = pt[0], pt[1], pt[2]\n",
    "            mask = np.zeros_like(img)\n",
    "            mask = cv.circle(mask, (int(a), int(b)), int(r), (255, 255, 255), -1)\n",
    "            img = cv.bitwise_and(img, mask)\n",
    "\n",
    "    # Extract HOG features\n",
    "    hog = extract_hog_features(opened_image)\n",
    "\n",
    "    # Predict the label\n",
    "    predicted_label = svm.predict(hog.reshape(1, -1))\n",
    "\n",
    "    return predicted_label[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import io\n",
    "\n",
    "# # Load the image (replace 'path_to_image.jpg' with the actual path)\n",
    "# image = io.imread(\"TSRD_Test_1/022_1_0005_1_j.png\")\n",
    "\n",
    "# # Predict the label\n",
    "# label = predict(svm, image)\n",
    "# print(f\"Predicted label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Training phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully preprocessed images\n",
      "Extracting features...\n"
     ]
    }
   ],
   "source": [
    "svm = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main (predict test images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels [22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 26, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 24, 24, 26, 26, 26, 24, 26, 22, 22, 22, 22, 22, 22, 22, 22, 26, 22, 22, 22, 22, 22, 22, 22, 26, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 26, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 26, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 24, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 22, 26, 26, 26, 24, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 24, 26, 26, 26, 26, 26, 26, 26, 26, 24, 26, 26, 26, 26, 22, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 22, 26, 26, 26, 24, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 24, 26, 26, 26, 26, 26, 26, 26, 26, 24, 26, 26, 26, 26, 22, 26, 26, 26, 26, 26, 54, 54, 25, 26, 25, 25, 54, 24, 54, 25, 26, 25, 24, 25, 54, 25, 25, 25, 26, 54, 24, 25, 25, 54, 24, 25, 26, 25, 54, 54, 25, 25, 25, 54, 25, 26, 54, 26, 25, 25, 25, 25, 25, 25, 24, 26, 26, 26, 26, 26, 26, 26, 25, 26, 26, 26, 26, 25, 26, 26, 26, 26, 25, 25, 22, 26, 26, 26, 24, 26, 26, 26, 26, 25, 26, 26, 25, 26, 26, 25, 26, 26, 26, 25, 26, 26, 26, 26, 54, 54, 25, 26, 25, 25, 54, 24, 54, 25, 26, 25, 24, 25, 54, 25, 25, 25, 26, 54, 24, 25, 25, 54, 24, 25, 26, 25, 54, 54, 25, 25, 25, 54, 25, 26, 54, 26, 25, 25, 25, 25, 25, 25, 24, 26, 26, 26, 26, 26, 26, 26, 25, 26, 26, 26, 26, 25, 26, 26, 26, 26, 25, 25, 22, 26, 26, 26, 24, 26, 26, 26, 26, 25, 26, 26, 25, 26, 26, 25, 26, 26, 26, 25, 26, 26, 26, 26, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 24, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 26, 26, 24, 24, 55, 55, 55, 55, 55, 55, 55, 55, 24, 55, 55, 24, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 26, 26, 24, 24, 55, 55, 55, 55, 55, 55, 55, 55, 24, 55, 55, 24, 55, 55, 55, 55, 24, 24, 24, 24, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 24, 24, 56, 56, 56]\n",
      "Filtered actual_labels    [22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56]\n",
      "Filtered predicted_labels [22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 26, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 24, 24, 26, 26, 26, 24, 26, 22, 22, 22, 22, 22, 22, 22, 22, 26, 22, 22, 22, 22, 22, 22, 22, 26, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 26, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 26, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 24, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 22, 26, 26, 26, 24, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 24, 26, 26, 26, 26, 26, 26, 26, 26, 24, 26, 26, 26, 26, 22, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 22, 26, 26, 26, 24, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 24, 26, 26, 26, 26, 26, 26, 26, 26, 24, 26, 26, 26, 26, 22, 26, 26, 26, 26, 26, 54, 54, 25, 26, 25, 25, 54, 24, 54, 25, 26, 25, 24, 25, 54, 25, 25, 25, 26, 54, 24, 25, 25, 54, 24, 25, 26, 25, 54, 54, 25, 25, 25, 54, 25, 26, 54, 26, 25, 25, 25, 25, 25, 25, 24, 26, 26, 26, 26, 26, 26, 26, 25, 26, 26, 26, 26, 25, 26, 26, 26, 26, 25, 25, 22, 26, 26, 26, 24, 26, 26, 26, 26, 25, 26, 26, 25, 26, 26, 25, 26, 26, 26, 25, 26, 26, 26, 26, 54, 54, 25, 26, 25, 25, 54, 24, 54, 25, 26, 25, 24, 25, 54, 25, 25, 25, 26, 54, 24, 25, 25, 54, 24, 25, 26, 25, 54, 54, 25, 25, 25, 54, 25, 26, 54, 26, 25, 25, 25, 25, 25, 25, 24, 26, 26, 26, 26, 26, 26, 26, 25, 26, 26, 26, 26, 25, 26, 26, 26, 26, 25, 25, 22, 26, 26, 26, 24, 26, 26, 26, 26, 25, 26, 26, 25, 26, 26, 25, 26, 26, 26, 25, 26, 26, 26, 26, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 24, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 26, 26, 24, 24, 55, 55, 55, 55, 55, 55, 55, 55, 24, 55, 55, 24, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 26, 26, 24, 24, 55, 55, 55, 55, 55, 55, 55, 55, 24, 55, 55, 24, 55, 55, 55, 55, 24, 24, 24, 24, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 24, 24, 56, 56, 56]\n",
      "Test Accuracy: 75.49%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          22       0.93      0.89      0.91        92\n",
      "          24       0.72      0.98      0.83       106\n",
      "          25       0.50      0.92      0.65        66\n",
      "          26       0.69      0.95      0.80       216\n",
      "          54       1.00      0.12      0.22       176\n",
      "          55       1.00      0.91      0.95       141\n",
      "          56       1.00      0.74      0.85        23\n",
      "\n",
      "    accuracy                           0.75       820\n",
      "   macro avg       0.83      0.79      0.74       820\n",
      "weighted avg       0.83      0.75      0.71       820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Predict the labels of the test dataset\n",
    "    predicted_labels = predict(svm)\n",
    "    print (\"predicted_labels\", predicted_labels)\n",
    "\n",
    "    # Get the actual labels\n",
    "    actual_labels = get_actual_labels(TEST_DATASET_PATH)\n",
    "\n",
    "    # Filter out labels equal to 54 and corresponding predictions\n",
    "    filtered_actual_labels = actual_labels\n",
    "\n",
    "    # for i in range (len(actual_labels)):\n",
    "    #     if actual_labels[i] != 54:\n",
    "    #         filtered_actual_labels.append(actual_labels[i])\n",
    "\n",
    "    # Evaluate Classifier\n",
    "    print(\"Filtered actual_labels   \", filtered_actual_labels)\n",
    "    print(\"Filtered predicted_labels\", predicted_labels)\n",
    "\n",
    "    if len(filtered_actual_labels) == len(predicted_labels):\n",
    "        accuracy = accuracy_score(filtered_actual_labels, predicted_labels)\n",
    "        print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(classification_report(filtered_actual_labels, predicted_labels))\n",
    "    else:\n",
    "        print(\"Error: Length mismatch between filtered labels!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'trained_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(svm, 'trained_model.pkl')\n",
    "print(\"Model saved as 'trained_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 22\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "svm = joblib.load('trained_model.pkl')\n",
    "\n",
    "# Load the image\n",
    "image_path = \"TSRD_Test_1/022_1_0004_1_j.png\"\n",
    "img = cv.imread(image_path)\n",
    "\n",
    "if img is None:\n",
    "    print(f\"Failed to load image at {image_path}\")\n",
    "else:\n",
    "    # Predict the label\n",
    "    label = predict_image(svm, img)\n",
    "    print(f\"Predicted label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import cv2 as cv\n",
    "import joblib\n",
    "import numpy as np\n",
    "from skimage.morphology import disk, opening\n",
    "from skimage.feature import hog\n",
    "\n",
    "\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "# Circles Hough transform\n",
    "def circles_hough_transform(image):\n",
    "    # gray = rgb2gray(image)\n",
    "    edges = canny_edge_detection(image)\n",
    "    circles = cv.HoughCircles(edges, cv.HOUGH_GRADIENT, dp=3, minDist=300, param1=50, param2=30, minRadius=30, maxRadius=150)\n",
    "    return circles\n",
    "\n",
    "#canny edge detection\n",
    "def canny_edge_detection(image):\n",
    "    edges = cv.Canny((image * 255).astype(np.uint8), 40, 80)\n",
    "    return edges\n",
    "\n",
    "# HOG\n",
    "def extract_hog_features(image):\n",
    "    # gray = rgb2gray(image)\n",
    "    hog_features = hog(image, \n",
    "                       orientations=9, \n",
    "                       pixels_per_cell=(8, 8), \n",
    "                       cells_per_block=(2, 2), \n",
    "                       block_norm='L2-Hys', \n",
    "                       visualize=False, \n",
    "                       feature_vector=True)\n",
    "    return hog_features\n",
    "\n",
    "def predict_image(svm, img):\n",
    "    \"\"\"\n",
    "    Predict the label of a single image using the given SVM model.\n",
    "\n",
    "    Args:\n",
    "        svm: Trained SVM model.\n",
    "        img: Input image as a numpy array.\n",
    "\n",
    "    Returns:\n",
    "        Predicted label for the input image.\n",
    "    \"\"\"\n",
    "    # Resize the image to match the expected dimensions\n",
    "    img = cv.resize(img, IMAGE_SIZE, interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray_image = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian filter with sigma=3\n",
    "    gaussian_blur = cv.GaussianBlur(gray_image, (7, 7), sigmaX=1, sigmaY=1)\n",
    "\n",
    "    # Perform opening morphology using a disk-shaped structuring element\n",
    "    structuring_element = disk(4)  # Disk of radius 4\n",
    "    opened_image = opening(gaussian_blur, structuring_element)\n",
    "\n",
    "    # Perform Hough Circle Transform\n",
    "    detected_circles = circles_hough_transform(opened_image)\n",
    "\n",
    "    # Crop the image to the circular region if circles are detected\n",
    "    if detected_circles is not None:\n",
    "        for pt in detected_circles[0, :]: \n",
    "            a, b, r = pt[0], pt[1], pt[2]\n",
    "            mask = np.zeros_like(img)\n",
    "            mask = cv.circle(mask, (int(a), int(b)), int(r), (255, 255, 255), -1)\n",
    "            img = cv.bitwise_and(img, mask)\n",
    "\n",
    "    # Extract HOG features\n",
    "    hog = extract_hog_features(opened_image)\n",
    "\n",
    "    # Predict the label\n",
    "    predicted_label = svm.predict(hog.reshape(1, -1))\n",
    "\n",
    "    \n",
    "        # Map label to prediction\n",
    "    label_map = {\n",
    "        22: \"Turn left\",\n",
    "        24: \"Turn right\",\n",
    "        25: \"Keep left\",\n",
    "        26: \"Keep right\",\n",
    "        55: \"Stop white bar\",\n",
    "        56: \"Stop sign\"\n",
    "    }\n",
    "\n",
    "    return label_map.get(predicted_label[0], \"Unknown\")\n",
    "\n",
    "    # return predicted_label[0]\n",
    "\n",
    "\n",
    "def load_image():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.png;*.jpg;*.jpeg\")])\n",
    "    if not file_path:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        img = cv.imread(file_path)\n",
    "        if img is None:\n",
    "            raise ValueError(\"Failed to load the image.\")\n",
    "\n",
    "        # Convert to RGB for displaying\n",
    "        img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img_pil = Image.fromarray(img_rgb)\n",
    "        img_tk = ImageTk.PhotoImage(img_pil)\n",
    "\n",
    "        # Update GUI with the image\n",
    "        image_label.configure(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "        image_label.file_path = file_path\n",
    "\n",
    "        file_name_label.config(text=f\"Loaded: {file_path.split('/')[-1]}\")\n",
    "\n",
    "        predict_button.config(state=tk.NORMAL)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Could not load image: {e}\")\n",
    "\n",
    "def make_prediction():\n",
    "    try:\n",
    "        file_path = image_label.file_path\n",
    "        img = cv.imread(file_path)\n",
    "\n",
    "        # Predict the label\n",
    "        label = predict_image(svm, img)\n",
    "\n",
    "        # map images\n",
    "\n",
    "        # Display the result\n",
    "        result_label.config(text=f\"Prediction: {label}\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Prediction failed: {e}\")\n",
    "\n",
    "# Initialize GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Image Prediction\")\n",
    "root.geometry(\"500x500\")\n",
    "\n",
    "# Load SVM model\n",
    "svm = joblib.load('trained_model.pkl')\n",
    "\n",
    "# GUI components\n",
    "frame = tk.Frame(root)\n",
    "frame.pack(pady=10)\n",
    "\n",
    "file_name_label = tk.Label(frame, text=\"No image loaded\", font=(\"Arial\", 14))\n",
    "file_name_label.pack()\n",
    "\n",
    "image_label = tk.Label(frame)\n",
    "image_label.pack()\n",
    "\n",
    "load_button = tk.Button(root, text=\"Load Image\", command=load_image, font=(\"Arial\", 12))\n",
    "load_button.pack(pady=5)\n",
    "\n",
    "predict_button = tk.Button(root, text=\"Predict\", command=make_prediction, font=(\"Arial\", 12), state=tk.DISABLED)\n",
    "predict_button.pack(pady=5)\n",
    "\n",
    "result_label = tk.Label(root, text=\"Prediction: None\", font=(\"Arial\", 14))\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Run the GUI\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
